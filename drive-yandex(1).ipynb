{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11356834,"sourceType":"datasetVersion","datasetId":7107451}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Read data example","metadata":{"id":"ULyIGnA4hVXi","editable":false}},{"cell_type":"code","source":"import os\nimport typing\nfrom tqdm import tqdm\nimport glob\nimport pandas as pd\nimport tensorflow as tf\nimport numpy as np\nimport json\n\nfrom keras.utils import  Sequence\n\n","metadata":{"id":"oDoV7ypBhVXq","executionInfo":{"status":"ok","timestamp":1743780895745,"user_tz":-180,"elapsed":3970,"user":{"displayName":"Kallen 14","userId":"05555523211482635477"}},"trusted":true,"editable":false,"execution":{"iopub.status.busy":"2025-04-21T06:24:03.340168Z","iopub.execute_input":"2025-04-21T06:24:03.340595Z","iopub.status.idle":"2025-04-21T06:24:03.345693Z","shell.execute_reply.started":"2025-04-21T06:24:03.340563Z","shell.execute_reply":"2025-04-21T06:24:03.344484Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"ROOT_DATA_FOLDER = r\"/kaggle/input/drive-redused\"\n\nTRAIN_DATASET_PATH = os.path.join(ROOT_DATA_FOLDER, r\"YaCupTrain\")\n\nTEST_DATASET_PATH = os.path.join(ROOT_DATA_FOLDER, r\"YaCupTest\")\nlabel_columns = ['x', 'y', 'yaw']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T06:24:05.172039Z","iopub.execute_input":"2025-04-21T06:24:05.172476Z","iopub.status.idle":"2025-04-21T06:24:05.177646Z","shell.execute_reply.started":"2025-04-21T06:24:05.172440Z","shell.execute_reply":"2025-04-21T06:24:05.176551Z"},"editable":false},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## Read Data","metadata":{"editable":false}},{"cell_type":"code","source":"\n# Load all ids of a dataset\n\ndef read_testcase_ids(dataset_path: str):\n    ids = [int(case_id) for case_id in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, case_id))]\n    return ids\n\nids = read_testcase_ids(TRAIN_DATASET_PATH)\nlen(ids)\n\ntrain_ids = np.random.choice(ids, size=round(0.70*len(ids)), replace=False, p=None)\ntest_ids = [el for el in ids if el not in train_ids]\n\n\nclass DataFilePaths:\n    def __init__(self, testcase_path: str):\n        self.testcase_path = testcase_path\n\n    def localization(self):\n        return os.path.join(self.testcase_path, 'localization.csv')\n\n    def control(self):\n        return os.path.join(self.testcase_path, 'control.csv')\n\n    def metadata(self):\n        return os.path.join(self.testcase_path, 'metadata.json')\n\n    # exists only for test_dataset\n    def requested_stamps(self):\n        return os.path.join(self.testcase_path, 'requested_stamps.csv')\n\n\ndef read_localization(localization_path: str):\n    return pd.read_csv(localization_path)\n\ndef read_control(control_path):\n    return pd.read_csv(control_path)\n\ndef read_metadata(metadata_path: str):\n    with open(metadata_path, 'r') as f:\n        data = json.load(f)\n    return data\n\ndef read_requested_stamps(requested_stamps_path: str):\n    return pd.read_csv(requested_stamps_path)\n\ndef read_testcase(dataset_path: str, testcase_id: str, is_test: bool = False):\n    testcase_path = os.path.join(dataset_path, str(testcase_id))\n    data_file_paths = DataFilePaths(testcase_path)\n\n    testcase_data = {}\n    testcase_data['localization'] = read_localization(data_file_paths.localization())\n    testcase_data['control'] = read_control(data_file_paths.control())\n    testcase_data['metadata'] = read_metadata(data_file_paths.metadata())\n    if is_test:\n        testcase_data['requested_stamps'] = read_requested_stamps(data_file_paths.requested_stamps())\n\n    return testcase_data\n\n\ndef read_testcases(dataset_path: str, is_test: bool = False, testcase_ids: typing.Iterable[int] = None):\n    result = {}\n    if testcase_ids is None:\n        testcase_ids = read_testcase_ids(dataset_path)\n\n    for testcase_id in tqdm(testcase_ids):\n        testcase = read_testcase(dataset_path, testcase_id, is_test=is_test)\n        result[testcase_id] = testcase\n    return result","metadata":{"id":"bCpSHxcNhVXv","trusted":true,"execution":{"iopub.status.busy":"2025-04-21T06:24:08.280147Z","iopub.execute_input":"2025-04-21T06:24:08.280519Z","iopub.status.idle":"2025-04-21T06:24:13.224244Z","shell.execute_reply.started":"2025-04-21T06:24:08.280490Z","shell.execute_reply":"2025-04-21T06:24:13.222908Z"},"editable":false},"outputs":[],"execution_count":4},{"cell_type":"code","source":"train_dataset = read_testcases(TRAIN_DATASET_PATH)\nlen(train_dataset)","metadata":{"id":"Z7nU5sPYhVXw","outputId":"9ef4241a-bc40-484a-8f2f-cae65e2104f4","trusted":true,"execution":{"iopub.status.busy":"2025-04-21T06:24:13.225485Z","iopub.execute_input":"2025-04-21T06:24:13.225798Z","iopub.status.idle":"2025-04-21T06:25:51.968983Z","shell.execute_reply.started":"2025-04-21T06:24:13.225774Z","shell.execute_reply":"2025-04-21T06:25:51.967894Z"},"editable":false},"outputs":[{"name":"stderr","text":"100%|██████████| 3884/3884 [01:38<00:00, 39.35it/s]\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"3884"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"\ntrain = {k: v for k, v in train_dataset.items() if k in train_ids}\ntest = {k: v for k, v in train_dataset.items() if k in test_ids}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T06:25:51.970830Z","iopub.execute_input":"2025-04-21T06:25:51.971350Z","iopub.status.idle":"2025-04-21T06:25:52.035776Z","shell.execute_reply.started":"2025-04-21T06:25:51.971320Z","shell.execute_reply":"2025-04-21T06:25:52.034873Z"},"editable":false},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"# Window Generate","metadata":{}},{"cell_type":"markdown","source":"## 1 dict to df + mixed bach size","metadata":{"editable":false}},{"cell_type":"code","source":"class WindowGenerator():\n  def __init__(self, input_width, label_width, shift,\n               train, val,\n               label_columns=None):\n    # Store the raw data.\n    self.train = train\n    self.val = test\n\n    train_df = self.dict_to_df(train)\n    val_df = self.dict_to_df(test)\n\n\n\n    \n    \n\n    # Work out the label column indices.\n    self.label_columns = label_columns\n    if label_columns is not None:\n      self.label_columns_indices = {name: i for i, name in\n                                    enumerate(label_columns)}\n    self.column_indices = {name: i for i, name in\n                           enumerate(train_df.columns)}\n\n    # Work out the window parameters.\n    self.input_width = input_width\n    self.label_width = label_width\n    self.shift = shift\n\n    self.total_window_size = input_width + shift\n\n    self.input_slice = slice(0, input_width)\n    self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n\n    self.label_start = self.total_window_size - self.label_width\n    self.labels_slice = slice(self.label_start, None)\n    self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n\n\n  def dict_to_df(self, dict_df):\n      for i in dict_df.keys():\n          return dict_df[i]['localization']\n      \n\n  def __repr__(self):\n    return '\\n'.join([\n        f'Total window size: {self.total_window_size}',\n        f'Input indices: {self.input_indices}',\n        f'Label indices: {self.label_indices}',\n        f'Label column name(s): {self.label_columns}'])","metadata":{"trusted":true,"editable":false,"execution":{"iopub.status.busy":"2025-04-21T06:25:52.037379Z","iopub.execute_input":"2025-04-21T06:25:52.037725Z","iopub.status.idle":"2025-04-21T06:25:52.045581Z","shell.execute_reply.started":"2025-04-21T06:25:52.037690Z","shell.execute_reply":"2025-04-21T06:25:52.044638Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## 2 dict to df + mixed bach size logic","metadata":{"editable":false}},{"cell_type":"code","source":"class WindowGenerator(Sequence):\n  def __init__(self, input_width, label_width, shift,\n               train, val,\n               label_columns=None, batch_size=32):\n    # Store the raw data.\n    self.train = train\n    self.val = test\n\n    # Work out the label column indices.\n    self.label_columns = label_columns\n    if label_columns is not None:\n      self.label_columns_indices = {name: i for i, name in\n                                    enumerate(label_columns)}\n    self.column_indices = {name: i for i, name in\n                           enumerate(train_df.columns)}\n\n    # Work out the window parameters.\n    self.input_width = input_width\n    self.label_width = label_width\n    self.shift = shift\n\n    self.total_window_size = input_width + shift\n\n    self.input_slice = slice(0, input_width)\n    self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n\n    self.label_start = self.total_window_size - self.label_width\n    self.labels_slice = slice(self.label_start, None)\n    self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n    self.batch_size =  batch_size\n    buch_for_buch = round(buch_data_len - label_width/shift) # quality of el from dict with we use for one buch\n\n\n\n  def __len__(self):\n    'Denotes the number of batches per epoch'\n    len_after_windows = train.keys()*buch_data_len/input_width*shift\n    return int(np.floor(len(len_after_windows) / self.batch_size))\n\n    \n  def on_epoch_end(self):\n    'Updates indexes after each epoch'\n    self.indexes = np.arange(len(self.)) #!!!!!\n    if self.shuffle == True:\n        np.random.shuffle(self.indexes)\n\n\n  def __getitem__(self, index):\n        'Generate one batch of data'\n    # Generate indexes of the batch\n    indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n    # Find list of IDs\n    list_IDs_temp = [k for k in indexes]\n\n    # Generate data\n    X, y = self.__data_generation(list_IDs_temp)\n\n    return X, y\n\n\n   def __data_generation(self, list_IDs_temp):\n        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n        # Initialization\n        batch_data = list() \n        batch_labels = list()\n        \n        # Generate data\n        for i in train.keys():\n            # Store sample\n\n            batch_data.append()\n            #Store class\n            batch_labels.append(label)\n            \n        return np.array(batch_data), np.array(batch_labels)\n      \n  def dict_to_df(self, dict_df):\n      for i in dict_df.keys():\n          return dict_df[i]['localization']\n\n\n  def split_window(self, features):\n    inputs = features[:, self.input_slice, :]\n    labels = features[:, self.labels_slice, :]\n    if self.label_columns is not None:\n      labels = tf.stack(\n          [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n           axis=-1)\n\n    # Slicing doesn't preserve static shape information, so set the shapes\n    # manually. This way the `tf.data.Datasets` are easier to inspect.\n    inputs.set_shape([None, self.input_width, None])\n    labels.set_shape([None, self.label_width, None])\n\n    return inputs, labels\n\n  def bach_prepare():\n      \n      \n\n  def __repr__(self):\n    return '\\n'.join([\n        f'Total window size: {self.total_window_size}',\n        f'Input indices: {self.input_indices}',\n        f'Label indices: {self.label_indices}',\n        f'Label column name(s): {self.label_columns}'])","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## With UP Class Logic","metadata":{"editable":false}},{"cell_type":"code","source":"class WindowGenerator():\n  def __init__(self, input_width, label_width, shift,\n               train_df, val_df,\n               label_columns=None):\n    # Store the raw data.\n    self.train_df = train_df\n    self.val_df = val_df\n\n\n    # Work out the label column indices.\n    self.label_columns = label_columns\n    if label_columns is not None:\n      self.label_columns_indices = {name: i for i, name in\n                                    enumerate(label_columns)}\n    self.column_indices = {name: i for i, name in\n                           enumerate(train_df.columns)}\n\n    # Work out the window parameters.\n    self.input_width = input_width\n    self.label_width = label_width\n    self.shift = shift\n\n    self.total_window_size = input_width + shift\n\n    self.input_slice = slice(0, input_width)\n    self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n\n    self.label_start = self.total_window_size - self.label_width\n    self.labels_slice = slice(self.label_start, None)\n    self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n\n  def __repr__(self):\n    return '\\n'.join([\n        f'Total window size: {self.total_window_size}',\n        f'Input indices: {self.input_indices}',\n        f'Label indices: {self.label_indices}',\n        f'Label column name(s): {self.label_columns}'])\n\n\n\n\nclass UPWindowGenerator():\n    def __init__(train_dict, val_dict,):\n        self.train_dict = train_dict\n        self.batch_size =  batch_size\n        #self.val_df = val_df\n\n    def get_items():\n        bach \n        for i in train_dict.keys():\n            \n            WindowGenerator(train_dict[i]['localization'])\n\n","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## step by step logic","metadata":{"editable":false}},{"cell_type":"code","source":"class WindowGenerator():\n  def __init__(self,train_df, input_width, label_width, shift,\n               label_columns=None):\n    # Store the raw data.\n    self.train_df = train_df\n\n\n    # Work out the label column indices.\n    self.label_columns = label_columns\n    if label_columns is not None:\n      self.label_columns_indices = {name: i for i, name in\n                                    enumerate(label_columns)}\n    self.column_indices = {name: i for i, name in\n                           enumerate(train_df.columns)}\n\n    # Work out the window parameters.\n    self.input_width = input_width\n    self.label_width = label_width\n    self.shift = shift\n\n    self.total_window_size = input_width + shift\n\n    self.input_slice = slice(0, input_width)\n    self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n\n    self.label_start = self.total_window_size - self.label_width\n    self.labels_slice = slice(self.label_start, None)\n    self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n\n  def __repr__(self):\n    return '\\n'.join([\n        f'Total window size: {self.total_window_size}',\n        f'Input indices: {self.input_indices}',\n        f'Label indices: {self.label_indices}',\n        f'Label column name(s): {self.label_columns}'])\n\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T06:25:52.046565Z","iopub.execute_input":"2025-04-21T06:25:52.046880Z","iopub.status.idle":"2025-04-21T06:25:52.068319Z","shell.execute_reply.started":"2025-04-21T06:25:52.046856Z","shell.execute_reply":"2025-04-21T06:25:52.067065Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def split_window(self, features):\n  inputs = features[:, self.input_slice, :]\n  labels = features[:, self.labels_slice, :]\n  if self.label_columns is not None:\n    labels = tf.stack(\n        [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n        axis=-1)\n\n  # Slicing doesn't preserve static shape information, so set the shapes\n  # manually. This way the `tf.data.Datasets` are easier to inspect.\n  inputs.set_shape([None, self.input_width, None])\n  labels.set_shape([None, self.label_width, None])\n\n  return inputs, labels\n\n\nWindowGenerator.split_window = split_window","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T06:25:52.069398Z","iopub.execute_input":"2025-04-21T06:25:52.069715Z","iopub.status.idle":"2025-04-21T06:25:52.089465Z","shell.execute_reply.started":"2025-04-21T06:25:52.069682Z","shell.execute_reply":"2025-04-21T06:25:52.088531Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"train_seq_X = []\ntrain_seq_y = []\n\nfor key in train.keys():\n    w2 = WindowGenerator(train[key]['localization'], input_width=5, label_width=5, shift=1, label_columns=['x','y','yaw'])\n    example_window = tf.stack([np.array(train[key]['localization'][:w2.total_window_size]),\n                           np.array(train[key]['localization'][100:100+w2.total_window_size]),\n                           np.array(train[key]['localization'][200:200+w2.total_window_size])\n                           ])\n  \n    X , y = w2.split_window(example_window)\n\n    train_seq_X.append(X)\n    train_seq_y.append(y)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T13:49:03.902906Z","iopub.execute_input":"2025-04-18T13:49:03.903266Z","iopub.status.idle":"2025-04-18T13:49:09.627832Z","shell.execute_reply.started":"2025-04-18T13:49:03.903218Z","shell.execute_reply":"2025-04-18T13:49:09.626751Z"}},"outputs":[],"execution_count":60},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"A = np.array(train_seq_X)\nA.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T13:49:09.655952Z","iopub.execute_input":"2025-04-18T13:49:09.656332Z","iopub.status.idle":"2025-04-18T13:49:09.677286Z","shell.execute_reply.started":"2025-04-18T13:49:09.656305Z","shell.execute_reply":"2025-04-18T13:49:09.676288Z"}},"outputs":[{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"(2719, 3, 5, 7)"},"metadata":{}}],"execution_count":62},{"cell_type":"code","source":"train_seq_X = []\ntrain_seq_y = []\n\nfor key in train.keys():\n    w2 = WindowGenerator(train[key]['localization'], input_width=5, label_width=5, shift=1, label_columns=['x','y','yaw'])\n    example_window = tf.stack([np.array(train[key]['localization'][:w2.total_window_size]),\n                           np.array(train[key]['localization'][100:100+w2.total_window_size]),\n                           np.array(train[key]['localization'][200:200+w2.total_window_size])\n                           ])\n  \n    X , y = w2.split_window(example_window)\n\n    for X_i, y_i in zip(X , y):\n\n         train_seq_X.append(X_i)\n         train_seq_y.append(y_i)\n    \n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T06:25:52.091653Z","iopub.execute_input":"2025-04-21T06:25:52.091923Z","iopub.status.idle":"2025-04-21T06:26:01.909560Z","shell.execute_reply.started":"2025-04-21T06:25:52.091900Z","shell.execute_reply":"2025-04-21T06:26:01.908514Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"train_seq_X= np.array(train_seq_X)\ntrain_seq_y = np.array(train_seq_y)\n## Add normalize","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T07:04:53.341619Z","iopub.execute_input":"2025-04-21T07:04:53.341945Z","iopub.status.idle":"2025-04-21T07:04:53.421560Z","shell.execute_reply.started":"2025-04-21T07:04:53.341920Z","shell.execute_reply":"2025-04-21T07:04:53.420498Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"train_seq_X.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T07:05:03.026485Z","iopub.execute_input":"2025-04-21T07:05:03.026873Z","iopub.status.idle":"2025-04-21T07:05:03.032716Z","shell.execute_reply.started":"2025-04-21T07:05:03.026839Z","shell.execute_reply":"2025-04-21T07:05:03.031744Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"(8157, 5, 7)"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"train_seq_y.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T07:05:13.821781Z","iopub.execute_input":"2025-04-21T07:05:13.822142Z","iopub.status.idle":"2025-04-21T07:05:13.827547Z","shell.execute_reply.started":"2025-04-21T07:05:13.822108Z","shell.execute_reply":"2025-04-21T07:05:13.826527Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"(8157, 5, 3)"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"B = np.array(train_seq_X)\nB.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T06:26:01.910587Z","iopub.execute_input":"2025-04-21T06:26:01.910876Z","iopub.status.idle":"2025-04-21T06:26:01.957954Z","shell.execute_reply.started":"2025-04-21T06:26:01.910844Z","shell.execute_reply":"2025-04-21T06:26:01.956947Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"(8157, 5, 7)"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"inputs = np.random.random((32, 10, 8))\n>>> lstm = keras.layers.LSTM(4)\n>>> output = lstm(inputs)\n>>> output.shape\n(32, 4)\n>>> lstm = keras.layers.LSTM(\n...     4, return_sequences=True, return_state=True)\n>>> whole_seq_output, final_memory_state, final_carry_state = lstm(inputs)\n>>> whole_seq_output.shape\n(32, 10, 4)\n>>> final_memory_state.shape\n(32, 4)\n>>> final_carry_state.shape\n(32, 4)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"inputs = np.random.random((32, 5, 7))\nlstm = keras.layers.LSTM(3, return_sequences=True, return_state=True)\nwhole_seq_output, final_memory_state, final_carry_state = lstm(inputs)\nwhole_seq_output.shape,\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T07:49:53.653571Z","iopub.execute_input":"2025-04-21T07:49:53.653911Z","iopub.status.idle":"2025-04-21T07:49:53.699386Z","shell.execute_reply.started":"2025-04-21T07:49:53.653881Z","shell.execute_reply":"2025-04-21T07:49:53.698430Z"}},"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"(TensorShape([32, 5, 3]),)"},"metadata":{}}],"execution_count":50},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lstm_model = tf.keras.models.Sequential([\n    # Shape [batch, time, features] => [batch, time, lstm_units]\n    tf.keras.layers.LSTM(512, return_sequences=True),\n    tf.keras.layers.LSTM(128, return_sequences=True),\n    tf.keras.layers.LSTM(3, return_sequences=True)\n    # Shape => [batch, time, features]\n    #tf.keras.layers.Dense(units=5,3)\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T08:15:19.734448Z","iopub.execute_input":"2025-04-21T08:15:19.734796Z","iopub.status.idle":"2025-04-21T08:15:19.752724Z","shell.execute_reply.started":"2025-04-21T08:15:19.734766Z","shell.execute_reply":"2025-04-21T08:15:19.751683Z"}},"outputs":[],"execution_count":66},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import keras","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T06:33:54.720539Z","iopub.execute_input":"2025-04-21T06:33:54.720895Z","iopub.status.idle":"2025-04-21T06:33:54.724990Z","shell.execute_reply.started":"2025-04-21T06:33:54.720867Z","shell.execute_reply":"2025-04-21T06:33:54.724009Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"lstm_model.compile(\n    optimizer=keras.optimizers.Adam(learning_rate=1e-5),\n    loss=keras.losses.SquaredHinge(),\n    metrics=[\n        keras.metrics.Accuracy(), keras.metrics.RootMeanSquaredError(), keras.metrics.CosineSimilarity()\n    ],\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T08:26:03.289183Z","iopub.execute_input":"2025-04-21T08:26:03.289594Z","iopub.status.idle":"2025-04-21T08:26:03.303184Z","shell.execute_reply.started":"2025-04-21T08:26:03.289563Z","shell.execute_reply":"2025-04-21T08:26:03.302357Z"}},"outputs":[],"execution_count":86},{"cell_type":"code","source":"losses.Tversky()\nSquaredHinge","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lstm_model.fit(train_seq_X, train_seq_y, epochs=20, batch_size=2028)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T08:26:05.747815Z","iopub.execute_input":"2025-04-21T08:26:05.748157Z","iopub.status.idle":"2025-04-21T08:27:25.984039Z","shell.execute_reply.started":"2025-04-21T08:26:05.748128Z","shell.execute_reply":"2025-04-21T08:27:25.983183Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/20\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 580ms/step - accuracy: 0.0000e+00 - cosine_similarity: -0.4171 - loss: 5262706.0000 - root_mean_squared_error: 11641.0127\nEpoch 2/20\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 595ms/step - accuracy: 0.0000e+00 - cosine_similarity: -0.4143 - loss: 5170926.0000 - root_mean_squared_error: 11829.5566\nEpoch 3/20\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 583ms/step - accuracy: 0.0000e+00 - cosine_similarity: -0.4117 - loss: 5117136.5000 - root_mean_squared_error: 11869.7197\nEpoch 4/20\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 580ms/step - accuracy: 0.0000e+00 - cosine_similarity: -0.4149 - loss: 5143760.0000 - root_mean_squared_error: 11630.1875\nEpoch 5/20\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 686ms/step - accuracy: 0.0000e+00 - cosine_similarity: -0.4135 - loss: 5178601.5000 - root_mean_squared_error: 11725.2979\nEpoch 6/20\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 578ms/step - accuracy: 0.0000e+00 - cosine_similarity: -0.4134 - loss: 5189556.5000 - root_mean_squared_error: 11690.2676\nEpoch 7/20\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 582ms/step - accuracy: 0.0000e+00 - cosine_similarity: -0.4159 - loss: 5192815.5000 - root_mean_squared_error: 11694.6777\nEpoch 8/20\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 583ms/step - accuracy: 0.0000e+00 - cosine_similarity: -0.4148 - loss: 5131314.0000 - root_mean_squared_error: 11776.2988\nEpoch 9/20\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 598ms/step - accuracy: 0.0000e+00 - cosine_similarity: -0.4114 - loss: 5088065.0000 - root_mean_squared_error: 11887.0020\nEpoch 10/20\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 588ms/step - accuracy: 0.0000e+00 - cosine_similarity: -0.4163 - loss: 5168158.5000 - root_mean_squared_error: 11661.7012\nEpoch 11/20\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 587ms/step - accuracy: 0.0000e+00 - cosine_similarity: -0.4146 - loss: 5156625.0000 - root_mean_squared_error: 11670.9766\nEpoch 12/20\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 593ms/step - accuracy: 0.0000e+00 - cosine_similarity: -0.4166 - loss: 5181323.0000 - root_mean_squared_error: 11616.9551\nEpoch 13/20\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 589ms/step - accuracy: 0.0000e+00 - cosine_similarity: -0.4147 - loss: 5139012.5000 - root_mean_squared_error: 11675.5547\nEpoch 14/20\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 653ms/step - accuracy: 0.0000e+00 - cosine_similarity: -0.4156 - loss: 5165789.0000 - root_mean_squared_error: 11781.2139\nEpoch 15/20\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 582ms/step - accuracy: 0.0000e+00 - cosine_similarity: -0.4151 - loss: 5147268.5000 - root_mean_squared_error: 11851.4629\nEpoch 16/20\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 583ms/step - accuracy: 0.0000e+00 - cosine_similarity: -0.4165 - loss: 5165469.0000 - root_mean_squared_error: 11700.3740\nEpoch 17/20\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 584ms/step - accuracy: 0.0000e+00 - cosine_similarity: -0.4151 - loss: 5109256.5000 - root_mean_squared_error: 11659.5430\nEpoch 18/20\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 579ms/step - accuracy: 0.0000e+00 - cosine_similarity: -0.4159 - loss: 5164074.0000 - root_mean_squared_error: 11760.5264\nEpoch 19/20\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 578ms/step - accuracy: 0.0000e+00 - cosine_similarity: -0.4168 - loss: 5131549.5000 - root_mean_squared_error: 11701.8057\nEpoch 20/20\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 587ms/step - accuracy: 0.0000e+00 - cosine_similarity: -0.4176 - loss: 5166296.5000 - root_mean_squared_error: 11721.9922\n","output_type":"stream"},{"execution_count":87,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x781c540264a0>"},"metadata":{}}],"execution_count":87},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lstm_model.compile(train_seq_X, train_seq_y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T06:31:21.745906Z","iopub.execute_input":"2025-04-21T06:31:21.746249Z","iopub.status.idle":"2025-04-21T06:31:21.752154Z","shell.execute_reply.started":"2025-04-21T06:31:21.746223Z","shell.execute_reply":"2025-04-21T06:31:21.751125Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"<Sequential name=sequential, built=False>"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_seq_X = tf.zeros([5,7,1],dtype=tf.dtypes.float64,)\ntrain_seq_y = tf.zeros([5,3,1],dtype=tf.dtypes.float64,)\nprint(train_seq_X.ndim, train_seq_X.shape)\nfor key in train.keys():\n    w2 = WindowGenerator(train[key]['localization'], input_width=5, label_width=5, shift=1, label_columns=['x','y','yaw'])\n    example_window = tf.stack([np.array(train[key]['localization'][:w2.total_window_size]),\n                           np.array(train[key]['localization'][100:100+w2.total_window_size]),\n                           np.array(train[key]['localization'][200:200+w2.total_window_size])\n                           ])\n  \n    X , y = w2.split_window(example_window)\n    #print(X)\n    for X_i, y_i in zip(X , y):\n        #print(X_i.ndim, X_i.shape)\n        train_seq_X = tf.concat([train_seq_X,X_i], 1 )\n        train_seq_y =  tf.concat([train_seq_y,y_i], 1 )\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T13:40:17.463333Z","iopub.execute_input":"2025-04-18T13:40:17.463718Z","iopub.status.idle":"2025-04-18T13:40:17.493819Z","shell.execute_reply.started":"2025-04-18T13:40:17.463686Z","shell.execute_reply":"2025-04-18T13:40:17.492567Z"}},"outputs":[{"name":"stdout","text":"3 (5, 7, 1)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-47-0c4c1729a434>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mX_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m#print(X_i.ndim, X_i.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mtrain_seq_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_seq_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mtrain_seq_y\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_seq_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5981\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5982\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5983\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__ConcatV2_N_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} ConcatOp : Ranks of all input tensors should match: shape[0] = [5,7,1] vs. shape[1] = [5,7] [Op:ConcatV2] name: concat"],"ename":"InvalidArgumentError","evalue":"{{function_node __wrapped__ConcatV2_N_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} ConcatOp : Ranks of all input tensors should match: shape[0] = [5,7,1] vs. shape[1] = [5,7] [Op:ConcatV2] name: concat","output_type":"error"}],"execution_count":47},{"cell_type":"code","source":"train_seq_X.shape()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T07:03:50.529502Z","iopub.execute_input":"2025-04-21T07:03:50.529832Z","iopub.status.idle":"2025-04-21T07:03:50.549568Z","shell.execute_reply.started":"2025-04-21T07:03:50.529808Z","shell.execute_reply":"2025-04-21T07:03:50.547856Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-0f2ea6501dd8>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_seq_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"],"ename":"AttributeError","evalue":"'list' object has no attribute 'shape'","output_type":"error"}],"execution_count":22},{"cell_type":"code","source":"\nprint(train_seq_X.ndim, train_seq_X.shape)\nfor key in train.keys():\n    w2 = WindowGenerator(train[key]['localization'], input_width=5, label_width=5, shift=1, label_columns=['x','y','yaw'])\n    example_window = tf.stack([np.array(train[key]['localization'][:w2.total_window_size]),\n                           np.array(train[key]['localization'][100:100+w2.total_window_size]),\n                           np.array(train[key]['localization'][200:200+w2.total_window_size])\n                           ])\n  \n    X , y = w2.split_window(example_window)\n    #print(X)\n    train_seq_X = tf.zeros([5,7],dtype=tf.dtypes.float64,)\n    train_seq_y = tf.zeros([5,3],dtype=tf.dtypes.float64,)\n    for X_i, y_i in zip(X , y):\n        #print(X_i.ndim, X_i.shape)\n        train_seq_X = tf.concat([train_seq_X,X_i], 0 )\n        train_seq_y =  tf.concat([train_seq_y,y_i], 0 )\n\ntrain_seq_X","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_seq_X.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T13:35:33.693780Z","iopub.execute_input":"2025-04-18T13:35:33.694103Z","iopub.status.idle":"2025-04-18T13:35:33.699250Z","shell.execute_reply.started":"2025-04-18T13:35:33.694077Z","shell.execute_reply":"2025-04-18T13:35:33.698453Z"}},"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"(285495,)"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_seq_y","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T13:25:58.830064Z","iopub.execute_input":"2025-04-18T13:25:58.830442Z","iopub.status.idle":"2025-04-18T13:25:58.836715Z","shell.execute_reply.started":"2025-04-18T13:25:58.830401Z","shell.execute_reply":"2025-04-18T13:25:58.835801Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(40790, 3), dtype=float64, numpy=\narray([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n       ...,\n       [ 2.20955557e+04, -6.52065807e+04,  2.06363593e+00],\n       [ 2.20954131e+04, -6.52063152e+04,  2.06305254e+00],\n       [ 2.20952699e+04, -6.52060482e+04,  2.06283024e+00]])>"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"train_seq_X = np.array([])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T13:28:46.890593Z","iopub.execute_input":"2025-04-18T13:28:46.890946Z","iopub.status.idle":"2025-04-18T13:28:46.895608Z","shell.execute_reply.started":"2025-04-18T13:28:46.890918Z","shell.execute_reply":"2025-04-18T13:28:46.894310Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"train_seq_X","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T13:28:48.551616Z","iopub.execute_input":"2025-04-18T13:28:48.551978Z","iopub.status.idle":"2025-04-18T13:28:48.557458Z","shell.execute_reply.started":"2025-04-18T13:28:48.551947Z","shell.execute_reply":"2025-04-18T13:28:48.556493Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"array([], dtype=float64)"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"\ntrain_seq_X = np.array([[]])\n#print(train_seq_X.ndim, train_seq_X.shape)\n#train_seq_y = np.array([])\nfor key in train.keys():\n    w2 = WindowGenerator(train[key]['localization'], input_width=5, label_width=5, shift=1, label_columns=['x','y','yaw'])\n    example_window = tf.stack([np.array(train[key]['localization'][:w2.total_window_size]),\n                           np.array(train[key]['localization'][100:100+w2.total_window_size]),\n                           np.array(train[key]['localization'][200:200+w2.total_window_size])\n                           ])\n  \n    X , y = w2.split_window(example_window)\n    #print(X)\n    for X_i, y_i in zip(X , y):\n        #print(X_i.ndim, X_i.shape)\n        train_seq_X = np.append(train_seq_X,X_i) #,axis=0)\n        #train_seq_y = np.append(train_seq_y,y_i, axis=0)\n\ntrain_seq_X","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T13:29:52.980796Z","iopub.execute_input":"2025-04-18T13:29:52.981184Z","iopub.status.idle":"2025-04-18T13:30:03.917406Z","shell.execute_reply.started":"2025-04-18T13:29:52.981150Z","shell.execute_reply":"2025-04-18T13:30:03.916550Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"array([ 0.00000000e+00, -3.51938598e+03, -1.39464479e+04, ...,\n        5.09623448e-03, -4.82397264e-03,  2.06305254e+00])"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"train_seq_X","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T12:59:53.019771Z","iopub.execute_input":"2025-04-17T12:59:53.020188Z","iopub.status.idle":"2025-04-17T12:59:53.030781Z","shell.execute_reply.started":"2025-04-17T12:59:53.020155Z","shell.execute_reply":"2025-04-17T12:59:53.029486Z"}},"outputs":[{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"array([[[6.76819439e-310, 6.76819439e-310, 4.93452746e-310,\n         4.93452746e-310, 0.00000000e+000, 0.00000000e+000,\n         4.93451962e-310],\n        [4.93451962e-310, 5.43472210e-323, 0.00000000e+000,\n         3.95252517e-323, 8.48798316e-314, 3.95252517e-323,\n         0.00000000e+000],\n        [2.47032823e-323, 2.12199584e-314, 0.00000000e+000,\n         2.47032823e-323, 1.23516411e-322, 0.00000000e+000,\n         2.47032823e-323],\n        [4.24399163e-314, 0.00000000e+000, 2.47032823e-323,\n         4.24399163e-314, 0.00000000e+000, 2.47032823e-323,\n         6.36598742e-314],\n        [0.00000000e+000, 2.47032823e-323, 5.08887615e-322,\n         0.00000000e+000, 2.47032823e-323, 8.48798321e-314,\n         0.00000000e+000],\n        [2.47032823e-323, 2.12199587e-314, 0.00000000e+000,\n         2.47032823e-323, 1.06099790e-313, 0.00000000e+000,\n         2.47032823e-323],\n        [1.06099790e-313, 0.00000000e+000, 2.47032823e-323,\n         2.33419537e-313, 0.00000000e+000, 2.47032823e-323,\n         2.54639495e-313]],\n\n       [[0.00000000e+000, 2.96439388e-323, 2.75859454e-313,\n         0.00000000e+000, 2.96439388e-323, 4.99006302e-322,\n         0.00000000e+000],\n        [2.96439388e-323, 1.06099790e-313, 0.00000000e+000,\n         2.96439388e-323, 1.48539706e-313, 0.00000000e+000,\n         0.00000000e+000],\n        [0.00000000e+000, 1.69759663e-313, 1.35062725e+131,\n         1.23516411e-322, 0.00000000e+000, 2.96439388e-323,\n         2.12199584e-314],\n        [0.00000000e+000, 2.96439388e-323, 1.23516411e-322,\n         0.00000000e+000, 2.96439388e-323, 1.27319748e-313,\n         0.00000000e+000],\n        [2.96439388e-323, 2.33419538e-313, 0.00000000e+000,\n         2.96439388e-323, 2.97079411e-313, 0.00000000e+000,\n         2.96439388e-323],\n        [4.24399165e-314, 0.00000000e+000, 2.96439388e-323,\n         1.23516411e-322, 0.00000000e+000, 2.96439388e-323,\n         3.39519327e-313],\n        [1.69759663e-313, 3.95252517e-323, 4.99006302e-322,\n         0.00000000e+000, 3.45845952e-323, 1.06099790e-313,\n         0.00000000e+000]],\n\n       [[3.45845952e-323, 1.48539706e-313, 0.00000000e+000,\n         3.45845952e-323, 1.90979622e-313, 0.00000000e+000,\n         3.45845952e-323],\n        [1.23516411e-322, 0.00000000e+000, 3.45845952e-323,\n         2.12199584e-314, 0.00000000e+000, 3.45845952e-323,\n         1.23516411e-322],\n        [0.00000000e+000, 3.45845952e-323, 1.48539706e-313,\n         0.00000000e+000, 3.45845952e-323, 1.48539706e-313,\n         0.00000000e+000],\n        [3.45845952e-323, 2.33419538e-313, 0.00000000e+000,\n         3.45845952e-323, 2.97079411e-313, 0.00000000e+000,\n         3.45845952e-323],\n        [1.13635099e-322, 0.00000000e+000, 3.45845952e-323,\n         4.24399165e-314, 0.00000000e+000, 3.45845952e-323,\n         1.23516411e-322],\n        [0.00000000e+000, 3.45845952e-323, 2.12199587e-314,\n         0.00000000e+000, 3.45845952e-323, 4.99006302e-322,\n         0.00000000e+000],\n        [3.95252517e-323, 1.06099790e-313, 0.00000000e+000,\n         3.95252517e-323, 1.48539706e-313, 0.00000000e+000,\n         3.95252517e-323]],\n\n       [[1.90979622e-313, 0.00000000e+000, 3.95252517e-323,\n         1.23516411e-322, 0.00000000e+000, 3.95252517e-323,\n         2.12199584e-314],\n        [0.00000000e+000, 3.95252517e-323, 1.23516411e-322,\n         0.00000000e+000, 3.95252517e-323, 1.69759664e-313,\n         0.00000000e+000],\n        [3.95252517e-323, 1.69759664e-313, 0.00000000e+000,\n         3.95252517e-323, 2.33419538e-313, 0.00000000e+000,\n         3.95252517e-323],\n        [2.97079411e-313, 0.00000000e+000, 3.95252517e-323,\n         1.13635099e-322, 0.00000000e+000, 3.95252517e-323,\n         4.24399165e-314],\n        [0.00000000e+000, 3.95252517e-323, 1.23516411e-322,\n         0.00000000e+000, 3.95252517e-323, 2.12199587e-314,\n         0.00000000e+000],\n        [3.95252517e-323, 6.36598742e-314, 0.00000000e+000,\n         2.96439388e-323, 2.12199587e-314, 0.00000000e+000,\n         2.96439388e-323],\n        [3.18299369e-313, 6.57818695e-313, 7.42698527e-313,\n         2.33419537e-313, 0.00000000e+000, 5.43472210e-323,\n         3.39519327e-313]],\n\n       [[0.00000000e+000, 5.43472210e-323, 3.18299369e-313,\n         0.00000000e+000, 5.43472210e-323, 2.12199587e-314,\n         0.00000000e+000],\n        [5.43472210e-323, 4.24399163e-314, 0.00000000e+000,\n         5.43472210e-323, 3.60739285e-313, 0.00000000e+000,\n         5.43472210e-323],\n        [3.81959243e-313, 0.00000000e+000, 5.43472210e-323,\n         4.03179201e-313, 0.00000000e+000, 6.42285340e-323,\n         3.60739285e-313],\n        [0.00000000e+000, 6.42285340e-323, 3.81959243e-313,\n         0.00000000e+000, 6.42285340e-323, 4.24399165e-314,\n         0.00000000e+000],\n        [6.42285340e-323, 3.35964639e-322, 0.00000000e+000,\n         6.42285340e-323, 0.00000000e+000, 0.00000000e+000,\n         0.00000000e+000],\n        [0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n         0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n         0.00000000e+000],\n        [0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n         0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n         0.00000000e+000]],\n\n       [[0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n         0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n         0.00000000e+000],\n        [0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n         0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n         0.00000000e+000],\n        [0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n         0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n         0.00000000e+000],\n        [0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n         0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n         0.00000000e+000],\n        [0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n         0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n         0.00000000e+000],\n        [0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n         0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n         0.00000000e+000],\n        [0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n         0.00000000e+000, 6.76804946e-310, 8.48798316e-314,\n         3.95252517e-323]],\n\n       [[0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n         0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n         0.00000000e+000],\n        [0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n         0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n         0.00000000e+000],\n        [0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n         0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n         0.00000000e+000],\n        [0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n         0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n         0.00000000e+000],\n        [0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n         0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n         0.00000000e+000],\n        [0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n         0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n         0.00000000e+000],\n        [0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n         0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n         9.88131292e-324]]])"},"metadata":{}}],"execution_count":68},{"cell_type":"code","source":"len(train_seq_y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T13:44:26.540452Z","iopub.execute_input":"2025-04-15T13:44:26.540818Z","iopub.status.idle":"2025-04-15T13:44:26.546235Z","shell.execute_reply.started":"2025-04-15T13:44:26.540779Z","shell.execute_reply":"2025-04-15T13:44:26.545424Z"},"editable":false},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"122355"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"train_seq_X","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T13:43:49.467471Z","iopub.execute_input":"2025-04-15T13:43:49.467923Z","iopub.status.idle":"2025-04-15T13:43:49.473995Z","shell.execute_reply.started":"2025-04-15T13:43:49.467890Z","shell.execute_reply":"2025-04-15T13:43:49.472953Z"},"editable":false},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"array([ 0.00000000e+00, -3.51938598e+03, -1.39464479e+04, ...,\n        3.81686862e-02, -2.76660030e-02, -7.57760663e-01])"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"w2 = WindowGenerator(train=train, val=test, label_columns=['x','y','yaw'], input_width=5, label_width=5, shift=1)","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"w2","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"w2 = WindowGenerator(train_df=train[3]['localization'], val_df=test[2]['localization'], label_columns=['x','y','yaw'], input_width=5, label_width=5, shift=1)","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"example_window = tf.stack([np.array(train[3]['localization'][:w2.total_window_size]),\n                           np.array(train[3]['localization'][100:100+w2.total_window_size]),\n                           np.array(train[3]['localization'][200:200+w2.total_window_size])\n                           ])\n\n","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"example_inputs, example_labels = w2.split_window(example_window)\n\nprint('All shapes are: (batch, time, features)')\nprint(f'Window shape: {example_window.shape}')\nprint(f'Inputs shape: {example_inputs.shape}')\nprint(f'Labels shape: {example_labels.shape}')\n","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def make_dataset(self, data):\n    data = np.array(el, dtype=np.float32)\n    ds = tf.keras.utils.timeseries_dataset_from_array(\n        data=data,\n        targets=None,\n        sequence_length=self.total_window_size,\n        sequence_stride=1,\n        shuffle=True,\n        batch_size=32,)\n\n    ds = ds.map(self.split_window)\n\n    return ds\n\nWindowGenerator.make_dataset = make_dataset","metadata":{"trusted":true,"_kg_hide-input":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(train)","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"@property\ndef train(self):\n    for i in train_ids:\n        train_df = train[i]['localization']\n        return self.make_dataset(self.train_df)\n\n\n\n@property\ndef example(self):\n  \"\"\"Get and cache an example batch of `inputs, labels` for plotting.\"\"\"\n  result = getattr(self, '_example', None)\n  if result is None:\n    # No example batch was found, so get one from the `.train` dataset\n    result = next(iter(self.train))\n    # And cache it for next time\n    self._example = result\n  return result","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"@property\ndef train(self):\n  return self.make_dataset(self.train_df)\n\n@property\ndef val(self):\n  return self.make_dataset(self.val_df)\n\n@property\ndef test(self):\n  return self.make_dataset(self.test_df)\n\n@property\ndef example(self):\n  \"\"\"Get and cache an example batch of `inputs, labels` for plotting.\"\"\"\n  result = getattr(self, '_example', None)\n  if result is None:\n    # No example batch was found, so get one from the `.train` dataset\n    result = next(iter(self.train))\n    # And cache it for next time\n    self._example = result\n  return result\n\nWindowGenerator.train = train\nWindowGenerator.val = val","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!install paramiko","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"wide_window = WindowGenerator( train_df=train[3]['localization'], val_df=test[2]['localization'], label_columns=['x','y','yaw'],\n    input_width=24, label_width=24, shift=1,)\n\nwide_window","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"MAX_EPOCHS = 20\n\ndef compile_and_fit(model, window, patience=2):\n  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n                                                    patience=patience,\n                                                    mode='min')\n\n  model.compile(loss=tf.losses.MeanSquaredError(),\n                optimizer=tf.optimizers.Adam(),\n                metrics=[tf.metrics.MeanAbsoluteError()])\n\n  history = model.fit(window.train, epochs=MAX_EPOCHS,\n                      validation_data=window.val,\n                      callbacks=[early_stopping])\n  return history","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lstm_model = tf.keras.models.Sequential([\n    # Shape [batch, time, features] => [batch, time, lstm_units]\n    tf.keras.layers.LSTM(32, return_sequences=True),\n    # Shape => [batch, time, features]\n    tf.keras.layers.Dense(units=1)\n])","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history = compile_and_fit(lstm_model, w2)","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataset[5]['control']['stamp_ns'] = train_dataset[5]['control']['stamp_ns']/10e9\ntrain_dataset[5]['localization']['stamp_ns'] = train_dataset[5]['localization']['stamp_ns']/10e9","metadata":{"id":"OeZZt97HhVXx","trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df = pd.DataFrame()\nfor el in train_dataset:\n    ","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataset[25]['control']","metadata":{"id":"KA260PoHhVXx","outputId":"da992b0b-83e6-4f25-8133-27a78752809e","trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataset[25]['control'].drop(columns='stamp_ns')","metadata":{"id":"NWQ_2soIhVXy","outputId":"a05bb37d-f45d-4a27-def6-ea9df8d34fc2","trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pd.concat([df1.set_index('A'),df2.set_index('A')], axis=1, join='inner').reset_index()\n","metadata":{"id":"bYBB0IozhVXy","trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"a = train_dataset[25]['localization'][74:1574]","metadata":{"id":"62-KhtXUhVXy","trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataset[25]['control'].drop(columns='stamp_ns')","metadata":{"id":"hSK_thHihVXy","outputId":"cf50cab2-49f8-4e1a-df75-7b5f71862f3a","trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"DfE1m6kEhVXz","trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pd.concat([train_dataset[25]['localization'][74:1574].reset_index(),train_dataset[25]['control'].drop(columns='stamp_ns').reset_index()], axis=1).reset_index().drop(columns=['index','level_0'])","metadata":{"id":"XvyaFXC9hVXz","outputId":"2787c9c0-3b78-4397-c79a-fed5a2d7bce8","trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_dataset = read_testcases(TEST_DATASET_PATH, is_test=True)\nlen(test_dataset)","metadata":{"id":"ClsonwZGhVXz","outputId":"9ffc45a7-bbc5-419f-ef20-bafc1083766b","trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"loc stams x y z roll pitch yaw 0--> LSTM --> next 1 loc stams x y z roll pitch yaw","metadata":{"id":"vONDOzGAhVXz","outputId":"7411393a-957f-45be-9477-02aa205d9640","trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"[el.values() for el in test_dataset.values()]","metadata":{"id":"nG782-XLhVXz","trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"65HgYCoYhVX0","trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# LSTM conv 1d","metadata":{"id":"K8wl-k42hVX0","trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from keras.layers.recurrent import LSTM","metadata":{"id":"aW03q1p8hVX0","trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.python.keras.layers.recurrent import LSTM, Bidirectional","metadata":{"id":"YbaN3leohVX0","trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"aq3X2UJthVX0","trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = Sequential([\n    LSTM(50, activation='tanh', return_sequences=True, input_shape=(10, 5)),  # First LSTM layer\n    LSTM(30, activation='tanh'),  # Second LSTM layer\n    Dense(1, activation='sigmoid')  # Output layer for binary classification\n])\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nmodel.summary()","metadata":{"id":"KiaEWVBbhVX0","trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tf.keras.layers.Bidirectional(\n    layer, merge_mode='concat'\n)\n","metadata":{"id":"v_agCQ89hVX1","trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Dataprepare():\n    def __init__(dataset):\n        self.dataset = dataset\n\n\n    def __len__(self):\n        return len(self.target)\n\n    def __getitem__(self, idx):\n        current_target = self.target[idx]\n        current_tweet = self.tweets[idx]\n        sequence = []\n        for word in current_tweet:\n            if word in self.word_to_idx.keys():\n                sequence.append(self.word_to_idx[word])\n\n        return {\n                'x': torch.tensor(sequence, dtype=torch.long),\n                'y': torch.tensor(current_target, dtype=torch.long)\n            }\n","metadata":{"id":"I8Uu5ILEhVX1","trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"DeTWySF8hVX1","trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"zvI7t1u1hVX1","trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"scaler = MinMaxScaler(feature_range=(0, 1))\nscaled_data = scaler.fit_transform(data)","metadata":{"id":"iWU3bmJLhVX1","trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_dataset(data, time_step=60):\n    X, y = [], []\n    for i in range(len(data) - time_step - 1):\n        X.append(data[i:(i + time_step), 0])\n        y.append(data[i + time_step, 0])\n    return np.array(X), np.array(y)\n\nX, y = create_dataset(scaled_data)\nX = X.reshape(X.shape[0], X.shape[1], 1)","metadata":{"id":"VRpukKQBhVX1","trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_size = int(len(X) * 0.8)\nX_train, X_test = X[:train_size], X[train_size:]\ny_train, y_test = y[:train_size], y[train_size:]","metadata":{"id":"RMl7fjevhVX2","trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_size = int(len(X) * 0.8)\nX_train, X_test = X[:train_size], X[train_size:]\ny_train, y_test = y[:train_size], y[train_size:]","metadata":{"id":"0aU-KS-ZhVX2","trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"cDyOoP6WhVX2","trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Dummy baseline","metadata":{"id":"6mgJHUS1hVX2","editable":false}},{"cell_type":"markdown","source":"### read test dataset","metadata":{"id":"3d0nSUy5hVX2","editable":false}},{"cell_type":"code","source":"import numpy as np\n\nNSECS_IN_SEC = 1000000000\n\ndef secs_to_nsecs(secs: float):\n    return int(secs * NSECS_IN_SEC)\n\ndef nsecs_to_secs(nsecs: int):\n    return float(nsecs) / NSECS_IN_SEC\n\ndef yaw_direction(yaw_value):\n    return np.array([np.cos(yaw_value), np.sin(yaw_value)])","metadata":{"id":"2NgfRhWLhVX2","trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install keras==2.10.0","metadata":{"id":"aF1vo_RhhVX9","outputId":"2ded429f-567a-4db7-eda6-10de07339d04","trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"auiYitr-hVX9","trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nnp.__version__","metadata":{"id":"XYF5YQ6RhVX9","outputId":"c4c94bb6-d1b8-4e42-edad-6d1f89f95bd4","trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### simple pose prediction logic without taking into account control states","metadata":{"id":"kfbYDFqLhVX-","editable":false}},{"cell_type":"code","source":"","metadata":{"id":"CMKRwdMGhVX-","trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def localization_df_to_poses(loc, contrl):\n    loc_contrl = pd.concat([loc[74:1574].reset_index(),contrl.drop(columns='stamp_ns').reset_index()], axis=1).reset_index().drop(columns=['index','level_0'])\n    poses = []\n    for stamp_ns, x, y, yaw,acceleration_level, steering, in zip(loc_contrl['stamp_ns'], loc_contrl['x'], loc_contrl['y'], loc_contrl['yaw'], loc_contrl['acceleration_level'],loc_contrl['steering']):\n        poses.append({'stamp_ns': stamp_ns, 'pos': np.array([x, y]), 'yaw': yaw})\n    return poses\n","metadata":{"id":"o2g_PX8FhVX-","trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def localization_df_to_poses(loc_df):\n    poses = []\n    for stamp_ns, x, y, yaw in zip(loc_df['stamp_ns'], loc_df['x'], loc_df['y'], loc_df['yaw']):\n        poses.append({'stamp_ns': stamp_ns, 'pos': np.array([x, y]), 'yaw': yaw})\n    return poses","metadata":{"id":"Ex6R_lNAhVX-","trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"localization_df_to_poses(loc_df)\n","metadata":{"id":"0R6NGBGIhVX-","trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nimport numpy as np","metadata":{"id":"tOJy-3a7hVX-","trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def localization_df_to_poses(loc_df):\n    poses = []\n    for stamp_ns, x, y, yaw in zip(loc_df['stamp_ns'], loc_df['x'], loc_df['y'], loc_df['yaw']):\n        poses.append({'stamp_ns': stamp_ns, 'pos': np.array([x, y]), 'yaw': yaw})\n    return poses\n\n# naive estimation of speed at last known localization pose\ndef dummy_estimate_last_speed(localization_poses):\n    last_pose = localization_poses[-1]\n\n    start_pose_idx = -1\n    for i, pose in enumerate(localization_poses, start=1-len(localization_poses)):\n        start_pose_idx = i\n        if nsecs_to_secs(last_pose['stamp_ns']) - nsecs_to_secs(pose['stamp_ns']) > 1.: # sec\n            break\n\n    start_pose = localization_poses[start_pose_idx]\n    dt_sec = nsecs_to_secs(last_pose['stamp_ns']) - nsecs_to_secs(start_pose['stamp_ns'])\n\n    if dt_sec > 1e-5:\n        return np.linalg.norm(last_pose['pos'][:2] - start_pose['pos'][:2]) / dt_sec\n    return 5. # some default value\n\ndef dummpy_predict_pose(last_loc_pose: dict, last_speed: float, prediction_stamp: int):\n    dt_sec = nsecs_to_secs(prediction_stamp) - nsecs_to_secs(last_loc_pose['stamp_ns'])\n    distance = dt_sec * last_speed\n    direction = yaw_direction(last_loc_pose['yaw'])\n    pos_translate = direction * distance\n    return {\"pos\": last_loc_pose['pos'] + pos_translate, 'yaw': last_loc_pose['yaw']}","metadata":{"id":"a7DB9tpLhVX_","trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def predict_testcase(testcase: dict):\n    loc_df = testcase['localization']\n    localization_poses = localization_df_to_poses(loc_df)\n\n    last_loc_pose = localization_poses[-1]\n    last_speed = dummy_estimate_last_speed(localization_poses)\n\n    predicted_poses = []\n    for stamp in testcase['requested_stamps']['stamp_ns']:\n        pose = dummpy_predict_pose(last_loc_pose, last_speed, stamp)\n        predicted_poses.append(pose)\n\n    predictions = {}\n    predictions['stamp_ns'] = testcase['requested_stamps']['stamp_ns']\n    predictions['x'] = [pose['pos'][0] for pose in predicted_poses]\n    predictions['y'] = [pose['pos'][1] for pose in predicted_poses]\n    predictions['yaw'] = [pose['yaw'] for pose in predicted_poses]\n    return pd.DataFrame(predictions)\n\ndef predict_test_dataset(test_dataset: dict):\n    predictions = {}\n    for testcase_id, testcase in tqdm(test_dataset.items()):\n        predictions[testcase_id] = predict_testcase(testcase)\n    return predictions","metadata":{"id":"z3wAYeHghVX_","trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### make prediction for requested stamps","metadata":{"id":"0bvydxAChVX_","editable":false}},{"cell_type":"code","source":"predictions = predict_test_dataset(train_dataset)\nlen(predictions)","metadata":{"id":"U9i8cnA_hVX_","outputId":"71cce3bb-ac19-4a5f-9957-ce0a1b4700bb","trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_predictions = predict_test_dataset(test_dataset)\nlen(test_predictions)","metadata":{"scrolled":true,"id":"uPoDBBjchVYA","outputId":"98538af8-eec6-43eb-f8e7-879d657db88d","trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_predictions","metadata":{"id":"u3oIJMXUhVYA","outputId":"588fcff9-0929-42b3-8d09-cba8ad5bcfd6","trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### write predictions","metadata":{"id":"LziiM8AuhVYA","editable":false}},{"cell_type":"code","source":"def write_predictions(dataset_predictions: dict, prediction_file_path: str):\n    prediction_list = []\n    for testcase_id, prediction in tqdm(dataset_predictions.items()):\n        prediction['testcase_id'] = [testcase_id] * len(prediction)\n        prediction_list.append(prediction)\n    predictions_df = pd.concat(prediction_list)\n    predictions_df = predictions_df.reindex(columns=[\"testcase_id\", \"stamp_ns\", \"x\", \"y\", \"yaw\"])\n    print(len(predictions_df))\n    predictions_df.to_csv(prediction_file_path, index=False, header=True)","metadata":{"id":"EmtU7NwghVYA","trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"write_predictions(test_predictions, os.path.join(ROOT_DATA_FOLDER, \"predictions.csv\"))","metadata":{"id":"e_RGLsQLhVYB","trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Calculate metric","metadata":{"id":"gdcQt2j1hVYB","editable":false}},{"cell_type":"markdown","source":"Let's describe final metric. As a first step, all predicted triples $(x,y,yaw)$ are being converted into 2 points $[(x_1, y_1), (x_2, y_2)]$ in the following way:\n$$\n(x_1, y_1) = (x, y), \\\\\n(x_2, y_2) = (x_1, y_1) + S \\times (yaw_x, yaw_y)\n$$  \n\nwhere $S = 1$. In other words, we build a directed segment of length $1$. These points then used in the metric calculation.\n\n\nMetric for a single pose (rmse):\n\n$$\npose\\_metric = \\sqrt{ \\frac{\\displaystyle\\sum_{j=1}^{k} {(x_j-\\hat{x_j})^2 + (y_j-\\hat{y_j})^2}}{k} }\n$$\n\nwhere $k$ - number of points that describe single pose (in our case $k=2$).\n\nMetric for a testcase:\n\n$$\ntestcase\\_metric = \\frac{1}{n}  \\displaystyle\\sum_{i=1}^{n}pose\\_metric_i\n$$\n\nwhere $n$ - number of localization points to predict.\n\nAnd, final metric for a whole dataset:\n\n$$\ndataset\\_metric = \\frac{1}{n}  \\displaystyle\\sum_{i=1}^{n}testcase\\_metric_i\n$$\n\nwhere $n$ - number of test cases.\n","metadata":{"id":"9y9Xz0j3hVYB","editable":false}},{"cell_type":"markdown","source":"### implementation of the metric calculation","metadata":{"id":"XtL6RI_MhVYB","editable":false}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nSEGMENT_LENGTH = 1.\n\ndef yaw_direction(yaw_value):\n    return np.array([np.cos(yaw_value), np.sin(yaw_value)])\n\ndef build_car_points(x_y_yaw):\n    directions = np.vstack(yaw_direction(x_y_yaw[:, -1]))\n\n    front_points = x_y_yaw[:, :-1] + SEGMENT_LENGTH * directions.T\n    points = np.vstack([x_y_yaw[:, :-1], front_points])\n    return points\n\ndef build_car_points_from_merged_df(df: pd.DataFrame):\n    points_gt = df[['x_gt', 'y_gt', 'yaw_gt']].to_numpy()\n    points_pred = df[['x_pred', 'y_pred', 'yaw_pred']].to_numpy()\n\n    points_gt = build_car_points(points_gt)\n    points_pred = build_car_points(points_pred)\n    return points_gt, points_pred\n\ndef calculate_metric_testcase(df: pd.DataFrame):\n    points_gt, points_pred = build_car_points_from_merged_df(df)\n\n    metric = np.mean(np.sqrt(2. * np.mean((points_gt - points_pred) ** 2, axis=1)))\n    return metric\n\ndef calculate_metric_dataset(ground_truth_df: pd.DataFrame, prediction_df: pd.DataFrame):\n    assert (len(ground_truth_df) == len(prediction_df))\n\n    df = ground_truth_df.merge(prediction_df, on=['testcase_id', 'stamp_ns'], suffixes=['_gt', '_pred'])\n\n    metric = df.groupby('testcase_id').apply(calculate_metric_testcase)\n    return np.mean(metric)","metadata":{"id":"G8A_yn3AhVYC","trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"jwdtOh5-hVYC","trusted":true,"editable":false},"outputs":[],"execution_count":null}]}